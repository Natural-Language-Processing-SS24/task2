{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec552b2a-4c71-4d79-996f-e8c3e432966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\papad\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/d3/1d/a257913c89572de61316461db91867f87519146e58132cdeace3d9ffbe1f/torch-2.3.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.3.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting optuna\n",
      "  Obtaining dependency information for optuna from https://files.pythonhosted.org/packages/15/da/68883911855d8b4d521f9a370e4e6aab8232b91c1d8d5a8348c4680c6642/optuna-3.6.1-py3-none-any.whl.metadata\n",
      "  Using cached optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\papad\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/3f/59/46818ebeb708234a60e42ccf409d20709e482519d2aa450b501ddbba4594/datasets-2.19.2-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.19.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\papad\\anaconda3\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\papad\\anaconda3\\lib\\site-packages (0.12.2)\n",
      "Collecting gradio\n",
      "  Obtaining dependency information for gradio from https://files.pythonhosted.org/packages/78/99/5d6f18958ee8f82b9bf858232cd48fc98a571a9cace053ea01198d8cefc1/gradio-4.36.1-py3-none-any.whl.metadata\n",
      "  Using cached gradio-4.36.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting wordcloud\n",
      "  Obtaining dependency information for wordcloud from https://files.pythonhosted.org/packages/f5/b0/247159f61c5d5d6647171bef84430b7efad4db504f0229674024f3a4f7f2/wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached wordcloud-1.9.3-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\papad\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\papad\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\papad\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\papad\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\papad\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\papad\\anaconda3\\lib\\site-packages (from torch) (2023.3.0)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Obtaining dependency information for mkl<=2021.4.0,>=2021.1.1 from https://files.pythonhosted.org/packages/fe/1c/5f6dbf18e8b73e0a5472466f0ea8d48ce9efae39bd2ff38cebf8dce61259/mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Obtaining dependency information for alembic>=1.5.0 from https://files.pythonhosted.org/packages/7f/50/9fb3a5c80df6eb6516693270621676980acd6d5a9a7efdbfa273f8d616c7/alembic-1.13.1-py3-none-any.whl.metadata\n",
      "  Using cached alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Obtaining dependency information for colorlog from https://files.pythonhosted.org/packages/f3/18/3e867ab37a24fdf073c1617b9c7830e06ec270b1ea4694a624038fc40a03/colorlog-6.8.2-py3-none-any.whl.metadata\n",
      "  Using cached colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\papad\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\papad\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from transformers) (1.24.28)\n",
      "Requirement already satisfied: requests in c:\\users\\papad\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: regex in c:\\users\\papad\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\papad\\anaconda3\\lib\\site-packages (from transformers) (0.2.0)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\papad\\anaconda3\\lib\\site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\papad\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Collecting requests (from transformers)\n",
      "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl.metadata\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: xxhash in c:\\users\\papad\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/50/15/b56e50e8debaf439f44befec5b2af11db85f6e0f344c3113ae0be0593a91/multiprocess-0.70.16-py311-none-any.whl.metadata\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\papad\\anaconda3\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/66/e8/bbbad5c7b49c68def42830f96c606e693bfa935a886740a363f04cb84e44/huggingface_hub-0.23.3-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (5.0.1)\n",
      "Collecting fastapi (from gradio)\n",
      "  Obtaining dependency information for fastapi from https://files.pythonhosted.org/packages/e6/33/de41e554e5a187d583906e10d53bfae5fd6c07e98cbf4fe5262bd37e739a/fastapi-0.111.0-py3-none-any.whl.metadata\n",
      "  Using cached fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (0.3.2)\n",
      "Collecting gradio-client==1.0.1 (from gradio)\n",
      "  Obtaining dependency information for gradio-client==1.0.1 from https://files.pythonhosted.org/packages/d5/d5/ee0814f51f81c8120495fd82a25aaeac4259058a3a61849bd7e575894fe1/gradio_client-1.0.1-py3-none-any.whl.metadata\n",
      "  Using cached gradio_client-1.0.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.24.1 (from gradio)\n",
      "  Obtaining dependency information for httpx>=0.24.1 from https://files.pythonhosted.org/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting importlib-resources<7.0,>=1.3 (from gradio)\n",
      "  Obtaining dependency information for importlib-resources<7.0,>=1.3 from https://files.pythonhosted.org/packages/75/06/4df55e1b7b112d183f65db9503bff189e97179b256e1ea450a3c365241e0/importlib_resources-6.4.0-py3-none-any.whl.metadata\n",
      "  Using cached importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (2.1.1)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Obtaining dependency information for orjson~=3.0 from https://files.pythonhosted.org/packages/80/86/4053cf342c0af3ca1d7a3d39b5b098d71d1ffd210fc4e62c68a6d5c261c7/orjson-3.10.4-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached orjson-3.10.4-cp311-none-win_amd64.whl.metadata (50 kB)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Obtaining dependency information for pydantic>=2.0 from https://files.pythonhosted.org/packages/e6/f5/80931903275942770f1112b524f1948f6d6ebd44725425025ca838800de2/pydantic-2.7.3-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.7.3-py3-none-any.whl.metadata (108 kB)\n",
      "Requirement already satisfied: pydub in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (0.0.9)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (0.4.8)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Obtaining dependency information for typer<1.0,>=0.12 from https://files.pythonhosted.org/packages/20/b5/11cf2e34fbb11b937e006286ab5b8cfd334fde1c8fa4dd7f491226931180/typer-0.12.3-py3-none-any.whl.metadata\n",
      "  Using cached typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: urllib3~=2.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio) (2.2.1)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Obtaining dependency information for uvicorn>=0.14.0 from https://files.pythonhosted.org/packages/b2/f9/e6f30ba6094733e4f9794fd098ca0543a19b07ac1fa3075d595bf0f1fb60/uvicorn-0.30.1-py3-none-any.whl.metadata\n",
      "  Using cached uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from gradio-client==1.0.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: click in c:\\users\\papad\\anaconda3\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\papad\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Obtaining dependency information for Mako from https://files.pythonhosted.org/packages/03/62/70f5a0c2dd208f9f3f2f9afd103aec42ee4d9ad2401d78342f75e9b8da36/Mako-1.3.5-py3-none-any.whl.metadata\n",
      "  Using cached Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.17.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\papad\\anaconda3\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\papad\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\papad\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/78/d4/e5d7e4f2174f8a4d63c8897d79eb8fe2503f7ecc03282fee1fa2719c2704/httpcore-1.0.5-py3-none-any.whl.metadata\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\papad\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\papad\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.2.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/78/71/6ce4136149cb42b98599d49c39b3a39dd6858b5f9307490998c40e26a51e/huggingface_hub-0.23.2-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/92/27/1a30d8082ef3c8615ae198b9d451fafffdab815b96727ec3c06befc27ebe/huggingface_hub-0.23.1-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/21/2b/516f82c5ba9beb184b24c11976be2ad5e80fb7fe6b2796c887087144445e/huggingface_hub-0.23.0-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/05/c0/779afbad8e75565c09ffa24a88b5dd7e293c92b74eb09df6435fc58ac986/huggingface_hub-0.22.2-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/b6/51/d418bb7bb9e32845d3cb4d526012ddf1fea6bb3d55b6a1880698e4b7f19f/huggingface_hub-0.22.1-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.22.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/89/66/1e0799583d8c844b59aa1a1d06ba26d50e8748d8b61b3ba8cbe4a0b26bc0/huggingface_hub-0.22.0-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.22.0-py3-none-any.whl.metadata (12 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/ab/28/d4b691840d73126d4c9845f8a22dad033ac872509b6d3a0d93b456eef424/huggingface_hub-0.21.4-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.21.4-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/47/8f/cf6683de320cf3873850ba48b7383db96958fe435b8e227db92119f6d867/huggingface_hub-0.21.3-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.21.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Obtaining dependency information for huggingface-hub>=0.21.2 from https://files.pythonhosted.org/packages/3d/c8/c3342c97848896df5d78d18abd94c558e457a4f02feec99a79989d8c30e0/huggingface_hub-0.21.2-py3-none-any.whl.metadata\n",
      "  Using cached huggingface_hub-0.21.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting fsspec[http]<=2024.3.1,>=2023.1.0 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]<=2024.3.1,>=2023.1.0 from https://files.pythonhosted.org/packages/93/6d/66d48b03460768f523da62a57a7e14e5e95fdf339d79e996ce3cecda2cdb/fsspec-2024.3.1-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Obtaining dependency information for intel-openmp==2021.* from https://files.pythonhosted.org/packages/6f/21/b590c0cc3888b24f2ac9898c41d852d7454a1695fbad34bee85dba6dc408/intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Obtaining dependency information for tbb==2021.* from https://files.pythonhosted.org/packages/7b/2d/1e1c70fae8ace27e6200fb71c2372a9aeac2baba474b1609d7d466e969b4/tbb-2021.12.0-py3-none-win_amd64.whl.metadata\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic>=2.0->gradio)\n",
      "  Obtaining dependency information for pydantic-core==2.18.4 from https://files.pythonhosted.org/packages/00/29/62236e5e19b92c1b908089589300e5834a8fcb5f870ae4f2a08b17782142/pydantic_core-2.18.4-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached pydantic_core-2.18.4-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\papad\\anaconda3\\lib\\site-packages (from tqdm->optuna) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Obtaining dependency information for rich>=10.11.0 from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
      "  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from boto3->transformers) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.6.0)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
      "  Obtaining dependency information for starlette<0.38.0,>=0.37.2 from https://files.pythonhosted.org/packages/fd/18/31fa32ed6c68ba66220204ef0be798c349d0a20c1901f9d4a794e08c76d8/starlette-0.37.2-py3-none-any.whl.metadata\n",
      "  Using cached starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
      "  Obtaining dependency information for fastapi-cli>=0.0.2 from https://files.pythonhosted.org/packages/a1/03/89bf615052aa5453c04d952225ded0b88aab6487b9c5f0c268939d13b860/fastapi_cli-0.0.4-py3-none-any.whl.metadata\n",
      "  Using cached fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from fastapi->gradio) (5.4.0)\n",
      "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
      "  Obtaining dependency information for email_validator>=2.0.0 from https://files.pythonhosted.org/packages/e4/60/b02cb0f5ee0be88bd4fbfdd9cc91e43ec2dfcc47fe064e7c70587ff58a94/email_validator-2.1.1-py3-none-any.whl.metadata\n",
      "  Using cached email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Obtaining dependency information for dill<0.3.9,>=0.3.0 from https://files.pythonhosted.org/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl.metadata\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of botocore to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting botocore<1.28.0,>=1.27.28 (from boto3->transformers)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/f9/73/aa345e22ce21e86fa99e8dc25ab7ae4fd73eedc4c365282c82fa6ba3f66f/botocore-1.27.96-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.96-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/09/04/687b1dc987718bac31b6e76e6658f2e6024aa002c2de7cda5a7b3f4d8400/botocore-1.27.95-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.95-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/4e/99/86f6402cfe0b9cb36086afd48b63f94aecc6f8946a6710c4694727c7622d/botocore-1.27.94-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.94-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/86/70/0843f9a93a97c631a13827f8b993078e595c6291f3147f02b52fa085d35e/botocore-1.27.93-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.93-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/24/c0/3f70efc9b8b588cbced1d0eebe479a81871c25bc95b83bca7aff03c2d7d0/botocore-1.27.92-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.92-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/70/74/296c59134f93718d20aa3766ba64eec2f4326e18075d52c9aadd88ce45a1/botocore-1.27.91-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.91-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/fb/cc/a19807b8504dbc8be5b3ab92f27169a614b929fe121a5deacfeb6136053b/botocore-1.27.90-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.90-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: pip is still looking at multiple versions of botocore to determine which version is compatible with other requirements. This could take a while.\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/28/33/5013ab7409efcbb580bc0420920abd2649337712790a648eb30a897c9fce/botocore-1.27.89-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.89-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/15/77/203d2a36e30a357814315cbfb06af0587e825b562b34e6ad7df11e6127ca/botocore-1.27.88-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.88-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/e7/51/603bb1e10f1ea57a23491e02a60eab28dbd1c018d3ba3b117e7a95a8a25b/botocore-1.27.87-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.87-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/4b/0a/d06fd7a3e933f539a7f7e2ae526be09bbe56250de50bdd8b0bc72e1f1c9b/botocore-1.27.86-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.86-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/b0/e7/deea9d49b05d26fb5b189483ad6a659a7100a2c9826145801d60c9ba0b8f/botocore-1.27.85-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.85-py3-none-any.whl.metadata (5.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/36/32/6ddb12143e32535550263514875db6d1a3ad50daf1377fbb1aac03a000aa/botocore-1.27.84-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.84-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/06/79/4b5829d8754c2229b0b0f19bf2dbdfe9a9a93039e9563951d926b626692f/botocore-1.27.83-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.83-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/ef/bf/5ead7178354461badb2d551795b0f607f53d6cef824a6b261846da03ad86/botocore-1.27.82-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.82-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/60/42/cb8265751a608a4e709cead1bba1a19a94384584759012d7ac8905aeecc1/botocore-1.27.81-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.81-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/d8/1b/1400757019a5006f8f5400eb2b5cfe372d44f5faf4901e0030e3e424c481/botocore-1.27.80-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.80-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/59/b4/fac56b12ffba913986ababf6ca140d22d995535f8a8132f51a684fb68d29/botocore-1.27.79-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.79-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/7e/b1/83db19ff165ddb463e774e89b5a587e4c7c72bbf94519cf1e1cb27d1b5eb/botocore-1.27.78-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.78-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/cd/37/152c1605f574e49accbd7c03f3fa013f7e180528772bd16b0e0daf354bca/botocore-1.27.77-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.77-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/54/fa/9502a6d39a7b7c5b262ecb90294b819b2217f948263e8fc2ac3227dba43c/botocore-1.27.76-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.76-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/3c/f5/563daa36ecc363fee7733bc94872f3f4701fcfb823b1a0ceaea0b9abad00/botocore-1.27.75-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.75-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/58/93/06c9bc911c0746b8e747b3d0c2206827b152d490cdd28701085dc8a4a940/botocore-1.27.74-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.74-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/59/52/771cd6ebc2c1c7b5844791f1ed163f27e19aeb06c3cdadb11c91469f0491/botocore-1.27.73-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.73-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/90/9f/c1049a60e3f8d2d16ec2e093f1d874c503d3b81baf40a69fb0f2aefd482f/botocore-1.27.72-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.72-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/df/99/e051928cf9d34eefcfe2c73427ae78bbeba43abb9b73f069e58b660f4563/botocore-1.27.71-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.71-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/58/11/4de2aa56633264a0c040b1b7158e5c39390029e6f6054f51b32f9375e7ba/botocore-1.27.70-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.70-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/3a/07/12c52d57f8b8183868f2d832409a76d9e42c7b694e4ddb09ef27f8cef575/botocore-1.27.69-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.69-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/81/78/698fc6bffad58e74c21745b4c4eea126e22ff028374dff62f2e77d6a1b33/botocore-1.27.68-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.68-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/94/d3/1df7cb5da1d892283e1fba48b61ac0876b89f93cee98ecb956732dc7f215/botocore-1.27.67-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.67-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/13/33/e2e8cdd1f1aab2fe7ce33beb19a92eed6b2e550fee0dbd86c3e8734d6f7c/botocore-1.27.66-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.66-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/f3/b3/fa6a4bc60f36d4a0c34c0a7eb429cfbde834567e4769bc5f3e68a49c6d01/botocore-1.27.65-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.65-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/d0/7a/6353c2156886edb2d3787bcf2c53c308296dec56c14547e411ac03677486/botocore-1.27.64-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.64-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/5b/31/de17ce54ccada53087efe5d751abb377ac570b3d4b219f17d187daa4579c/botocore-1.27.63-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.63-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/ab/dd/3458ba5d36f464bb4fe0fdcc9636b621386cb857ee1f66a5e397656e395a/botocore-1.27.62-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.62-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/39/89/568d63106e44d000d62a11abf8b1eb90999a66873b718db40ec0b24e5aa7/botocore-1.27.61-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.61-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/6a/dc/ba3779f41857137430e46f348030148b8e4bc311bfa5f9b4a9a7b1bf6e32/botocore-1.27.60-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.60-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/3f/8b/5e0909ec4efa6c83ab108f5e07e274ae4f346c3f0307fc8f5e4cb766b505/botocore-1.27.58-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.58-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/5a/46/08723a3e20a1c86b85e5eecb1a7ff580053d3dc7bbf4224cc20c67dcda55/botocore-1.27.57-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.57-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/9b/56/02ba314d2cbaecbf636196d806519290d05648e129884b8db3e1055e08ae/botocore-1.27.56-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.56-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/f1/3c/7bf0f6fabc9cb05758b10fe8c688d3f0540bb899abd1cdc4072242ee0b73/botocore-1.27.55-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.55-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/f5/02/57c8cdad5574f6cbcba273e6d4f2c00448431c984b2a231531f7c4ee9b4c/botocore-1.27.54-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.54-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/4d/ee/ac237fb39c21f212eb0174f1a0b68b568744a26fb3e4cbc19147ef318169/botocore-1.27.53-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.53-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/bc/9e/264835da6d66e2d061ff20c33ac3af5797b150197bc679ea08c34fd120a7/botocore-1.27.52-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.52-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/65/2a/a141513426d9252e29a9b5560c9d183f94959b7a6f4161ffc0a1b64edaf5/botocore-1.27.51-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.51-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/a2/72/08fdbca030b7a0b472d490f87849b72239b9fa5dd8e668bcfcf8e2be11b5/botocore-1.27.50-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.50-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/4c/42/87bd73b02ef4f42747ef0ecc3904e3bb1d02cfa8ede575b9324f5be6b1d5/botocore-1.27.49-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.49-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/20/1b/3230d4a0bae44f6bd1aeea9d757958cf84a0501613e1a76ecc6c82222b97/botocore-1.27.48-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/ea/6c/2ef806acc8d5b126646f52a74d62cf8ddc5525f5f5ace7f5654966c2617b/botocore-1.27.47-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.47-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/62/e5/d9e3426e309ad69967ae775c87e0d80d2446217bd1971b83bd0d92d02c2a/botocore-1.27.46-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.46-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/94/0d/7d82e2f28a3503c48c00beb0f07d0332f88bc1d250bb8018ff8c8e29854c/botocore-1.27.45-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.45-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/14/3d/5c3c17d4b595688db9820beff93275748d1a0b3987e559b10188b32d89e5/botocore-1.27.44-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/c6/1f/27ad4315b34715c08d5df65bd67aed48ce60c449a7938f7f20973ab6623a/botocore-1.27.43-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.43-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/b7/13/dc16bd71dffca9a4f9b9024a63ba1531c3352d4051d99492550f295ad86c/botocore-1.27.42-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.42-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/81/4e/17d147e77109073f5a727d624341cda3b1d090b50758c7856855e6f43819/botocore-1.27.41-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.41-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/0d/02/c86556b611cc4e1d402a646f6561f57d32b33445888b8e2513878aa46666/botocore-1.27.40-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.40-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/c2/d4/59b7625662752c2b8e3dd88dea15695e9c863afbd78bf7ad894779479841/botocore-1.27.39-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.39-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/d2/ba/92d7bb53556b262c03efaf061235eb5e37ea5eb120e0329242dfc3610350/botocore-1.27.38-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.38-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/e4/f5/5e95e99d847252b08554ffcc268d5d0d88de153efd85644d9fc8fa5e889a/botocore-1.27.37-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.37-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/9d/6f/888a9673d1a6fd4fe2094c458f8814c4523c3569fc4fe83d207815b4be84/botocore-1.27.36-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.36-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/b9/0d/3563502f1455decd5cc9a172724d5421829fc19d4b72f43c3b23a123c112/botocore-1.27.35-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.35-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/f9/23/2c55d2b7b09c1589731bcb5cfd271cdb45a0ea3afc53ec89eee374909e64/botocore-1.27.34-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.34-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/6a/66/0d01fb41af6696396aad34620adbfc26320d91e1ea5cdb993fe14563043b/botocore-1.27.33-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.33-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/20/3c/0735a78e459e48a543d4a656f7a87d9922448433978f546754f4283a17c9/botocore-1.27.32-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.32-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/29/b7/4f3e0bd6c82e2d7cb3390a405af27a2da458a7abcbd8315a5d14950fbac1/botocore-1.27.31-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.31-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/38/93/7302e89ec54032cc6373c22938b91cef1f8bb86505b4c06e1f0fcaa520af/botocore-1.27.30-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.30-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/7a/a4/ddba2e02f42fa6a3eda50e1718ccc120d325b2240930daeac7b6c1ce62a2/botocore-1.27.29-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.29-py3-none-any.whl.metadata (5.9 kB)\n",
      "  Obtaining dependency information for botocore<1.28.0,>=1.27.28 from https://files.pythonhosted.org/packages/fa/9e/f7662cd2c326b74eee8bb91e2bf3ea61f2b2d62738863d53fe801dcfdeca/botocore-1.27.28-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.27.28-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting boto3 (from transformers)\n",
      "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/5f/6a/a76adf7e28a71cc7c22376b01ffa3373b32d3e199cee3dbd86ee71e173c7/boto3-1.34.123-py3-none-any.whl.metadata\n",
      "  Using cached boto3-1.34.123-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.123 (from boto3->transformers)\n",
      "  Obtaining dependency information for botocore<1.35.0,>=1.34.123 from https://files.pythonhosted.org/packages/63/2d/ebdbe38d40b18d97fb921bb6929d8e9c991eb7ae4ecc4323c40b0209d9e0/botocore-1.34.123-py3-none-any.whl.metadata\n",
      "  Using cached botocore-1.34.123-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->transformers)\n",
      "  Obtaining dependency information for s3transfer<0.11.0,>=0.10.0 from https://files.pythonhosted.org/packages/83/37/395cdb6ee92925fa211e55d8f07b9f93cf93f60d7d4ce5e66fd73f1ea986/s3transfer-0.10.1-py3-none-any.whl.metadata\n",
      "  Using cached s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
      "  Obtaining dependency information for dnspython>=2.0.0 from https://files.pythonhosted.org/packages/87/a1/8c5287991ddb8d3e4662f71356d9656d91ab3a36618c3dd11b280df0d255/dnspython-2.6.1-py3-none-any.whl.metadata\n",
      "  Using cached dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
      "  Obtaining dependency information for httptools>=0.5.0 from https://files.pythonhosted.org/packages/14/e4/20d28dfe7f5b5603b6b04c33bb88662ad749de51f0c539a561f235f42666/httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from uvicorn>=0.14.0->gradio) (0.21.0)\n",
      "Collecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
      "  Obtaining dependency information for watchfiles>=0.13 from https://files.pythonhosted.org/packages/2b/8b/93f4e3ed0d578676b3c2e9d4ebf0b51237f4a96bbe3830b146662cb249da/watchfiles-0.22.0-cp311-none-win_amd64.whl.metadata\n",
      "  Using cached watchfiles-0.22.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\papad\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Using cached torch-2.3.1-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "Using cached optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "Using cached datasets-2.19.2-py3-none-any.whl (542 kB)\n",
      "Using cached gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
      "Using cached gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
      "Using cached wordcloud-1.9.3-cp311-cp311-win_amd64.whl (300 kB)\n",
      "Using cached alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "Using cached huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached orjson-3.10.4-cp311-none-win_amd64.whl (139 kB)\n",
      "Using cached pydantic-2.7.3-py3-none-any.whl (409 kB)\n",
      "Using cached pydantic_core-2.18.4-cp311-none-win_amd64.whl (1.9 MB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "Using cached uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "Using cached boto3-1.34.123-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.34.123-py3-none-any.whl (12.3 MB)\n",
      "Using cached colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Using cached fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Using cached fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "Using cached s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "Using cached starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "Using cached Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "Using cached dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "Using cached httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "Using cached watchfiles-0.22.0-cp311-none-win_amd64.whl (281 kB)\n",
      "Installing collected packages: tbb, intel-openmp, requests, pydantic-core, orjson, mkl, Mako, importlib-resources, httptools, h11, fsspec, dnspython, dill, colorlog, annotated-types, watchfiles, uvicorn, torch, starlette, rich, pydantic, multiprocess, huggingface-hub, httpcore, email_validator, botocore, alembic, wordcloud, typer, s3transfer, optuna, httpx, gradio-client, fastapi-cli, datasets, boto3, fastapi, gradio\n",
      "  Attempting uninstall: tbb\n",
      "    Found existing installation: TBB 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'TBB'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "#!pip install optuna transformers scikit-learn gradio pandas\n",
    "!pip install pandas torch optuna transformers datasets matplotlib seaborn gradio wordcloud nltk scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8be879-1453-4267-93e7-bbda62004b69",
   "metadata": {},
   "source": [
    "RoBERTa:\n",
    "\n",
    "> Why: RoBERTa has shown excellent performance across various NLP tasks, often outperforming BERT due to its robust optimization techniques and larger training corpus. It handles nuances in text very well, which is crucial for sentiment analysis.\n",
    "    Strengths: Strong performance on a wide range of tasks, robust pre-training.\n",
    "\n",
    "DistilBERT:\n",
    "\n",
    "> Why: DistilBERT is a distilled version of BERT that retains much of BERT's performance while being faster and more resource-efficient. It provides a good trade-off between performance and computational efficiency.\n",
    "    Strengths: Faster and lighter than BERT, making it suitable for applications where speed and resource usage are considerations.\n",
    "\n",
    "Electra:\n",
    "\n",
    "> Why: Electra uses a different pre-training approach where the model learns to distinguish real input tokens from fake ones generated by another model. This approach is computationally efficient and leads to strong performance.\n",
    "    Strengths: Computationally efficient, strong performance, particularly effective on downstream tasks after pre-training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc0b96",
   "metadata": {},
   "source": [
    "Train and Evaluate All Models:\n",
    "\n",
    "> Train each model with default hyperparameters and evaluate their performance on the validation set.\n",
    "\n",
    "Select the Best Model:\n",
    "\n",
    "> Select the model with the highest F1 score on the validation set.\n",
    "\n",
    "Fine-Tune the Best Model Using Optuna:\n",
    "\n",
    "> Use Optuna to optimize the hyperparameters for the best-performing model.\n",
    "\n",
    "Store All Models and Tokenizers:\n",
    "\n",
    "> Store the trained models and their tokenizers in the models dictionary for use during prediction.\n",
    "\n",
    "Predict Function:\n",
    "\n",
    "> The predict function takes a model, tokenizer, and text input, and returns the predicted label.\n",
    "\n",
    "Predict Sample Function:\n",
    "\n",
    "> The predict_sample function takes a sample index, retrieves the sample text, and gets predictions from all models, including the fine-tuned model.\n",
    "    The function returns the text, ground truth label, and predictions from each model.\n",
    "\n",
    "Gradio Interface:\n",
    "\n",
    "> Use the Gradio interface to select a sample and display predictions from all models, including the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c32cc71b-ffab-4fef-8a49-c442c0861f11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     AutoTokenizer,\n\u001b[0;32m      7\u001b[0m     RobertaForSequenceClassification,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     EarlyStoppingCallback\n\u001b[0;32m     14\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import optuna\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    DistilBertForSequenceClassification,\n",
    "    ElectraForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gradio as gr\n",
    "import logging\n",
    "import numpy as np\n",
    "import json\n",
    "import yaml\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger('Sentiment-Analysis')\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    logger.info(f\"Using device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "model_names = {\n",
    "    'RoBERTa': ('roberta-base', RobertaForSequenceClassification),\n",
    "    'DistilBERT': ('distilbert-base-uncased', DistilBertForSequenceClassification),\n",
    "    'Electra': ('google/electra-base-discriminator', ElectraForSequenceClassification)\n",
    "}\n",
    "\n",
    "# Load abbreviations from the YAML file\n",
    "with open('./data/abbreviations.yaml', 'r') as file:\n",
    "    abbreviations = yaml.safe_load(file)\n",
    "\n",
    "def replace_abbreviations(text):\n",
    "    for abbr, full_form in abbreviations.items():\n",
    "        text = text.replace(abbr, full_form)\n",
    "    return text\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset class for sentiment analysis.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def validate_labels(labels):\n",
    "    unique_labels = set(labels)\n",
    "    logger.info(f\"Unique labels: {unique_labels}\")\n",
    "    assert all(label in [0, 1, 2, 3, 4] for label in unique_labels), \"Labels are out of the expected range.\"\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labels = p.label_ids\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    return {\n",
    "        'eval_accuracy': accuracy,\n",
    "        'eval_precision': precision,\n",
    "        'eval_recall': recall,\n",
    "        'eval_f1': f1\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(labels, preds, model_name):\n",
    "    conf_mat = confusion_matrix(labels, preds)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()  # Adjust layout to fit all elements\n",
    "    plt.show()\n",
    "\n",
    "def train_model(model_name, train_df, learning_rate=5e-5, batch_size=16, num_epochs=3, use_early_stopping=False):\n",
    "    logger.info(f\"Training model: {model_name}\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_names[model_name][0])\n",
    "    model_class = model_names[model_name][1]\n",
    "    model = model_class.from_pretrained(model_names[model_name][0], num_labels=5)\n",
    "\n",
    "    # Preprocess data and split into training and validation sets\n",
    "    train_df['text'] = train_df['text'].apply(replace_abbreviations)  # Replace abbreviations\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        train_df['text'].tolist(), train_df['label'].tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "    validate_labels(train_labels)\n",
    "    validate_labels(val_labels)\n",
    "\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "    train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "    val_dataset = SentimentDataset(val_encodings, val_labels)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        load_best_model_at_end=use_early_stopping,\n",
    "        metric_for_best_model=\"eval_f1\",\n",
    "        greater_is_better=True,\n",
    "    )\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)] if use_early_stopping else []\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "\n",
    "    # Save the model and tokenizer\n",
    "    model.save_pretrained(f\"./models/{model_name}\")\n",
    "    tokenizer.save_pretrained(f\"./models/{model_name}\")\n",
    "\n",
    "    # Save evaluation results\n",
    "    eval_results['predictions'] = predictions.predictions.tolist()  # Convert to list for serialization\n",
    "    eval_results['labels'] = val_labels  # Add true labels for confusion matrix generation\n",
    "    with open(f\"./models/{model_name}_eval_results.json\", \"w\") as f:\n",
    "        json.dump(eval_results, f)\n",
    "\n",
    "    # Remove the 'predictions' and 'labels' keys for logging\n",
    "    eval_results_to_log = {k: v for k, v in eval_results.items() if k not in ['predictions', 'labels']}\n",
    "    \n",
    "    logger.info(f\"Evaluation results for {model_name}: {eval_results_to_log}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    predictions = np.argmax(np.array(eval_results['predictions']), axis=1)\n",
    "    logger.info(f\"Confusion matrix data - Labels: {eval_results['labels'][:10]} Predictions: {predictions[:10]}\")\n",
    "    plot_confusion_matrix(eval_results['labels'], predictions, model_name)\n",
    "\n",
    "    return model, tokenizer, eval_results\n",
    "\n",
    "def load_model(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f\"./models/{model_name}\")\n",
    "    model_class = model_names[model_name][1]\n",
    "    model = model_class.from_pretrained(f\"./models/{model_name}\")\n",
    "    # Load evaluation results\n",
    "    with open(f\"./models/{model_name}_eval_results.json\", \"r\") as f:\n",
    "        eval_results = json.load(f)\n",
    "    \n",
    "    # Remove the 'predictions' and 'labels' keys for logging\n",
    "    eval_results_to_log = {k: v for k, v in eval_results.items() if k not in ['predictions', 'labels']}\n",
    "    \n",
    "    logger.info(f\"Loaded evaluation results for {model_name}: {eval_results_to_log}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    predictions = np.argmax(np.array(eval_results['predictions']), axis=1)\n",
    "    logger.info(f\"Confusion matrix data - Labels: {eval_results['labels'][:10]} Predictions: {predictions[:10]}\")\n",
    "    plot_confusion_matrix(eval_results['labels'], predictions, model_name)\n",
    "    \n",
    "    return model, tokenizer, eval_results\n",
    "\n",
    "def objective(trial):\n",
    "    model_name = best_model_name  # Use the best model selected from initial training\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 16, 32)\n",
    "    train_df = pd.read_csv('./data/Sentiment_Training.csv', sep=';')\n",
    "    _, _, eval_results = train_model(model_name, train_df, learning_rate, batch_size)\n",
    "    return eval_results['eval_f1']\n",
    "\n",
    "# Load the data\n",
    "train_df = pd.read_csv('./data/Sentiment_Training.csv', sep=';')\n",
    "test_df = pd.read_csv('./data/Sentiment_Test.csv', sep=';')\n",
    "\n",
    "# Explorative Datenanalyse (EDA)\n",
    "# Display the first few rows and information of the training dataset\n",
    "print(\"First few rows of the training dataset:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nInformation about the training dataset:\")\n",
    "print(train_df.info())\n",
    "\n",
    "# Calculate text length\n",
    "train_df['text_length'] = train_df['text'].apply(len)\n",
    "print(\"\\nStatistics of text lengths in the training dataset:\")\n",
    "print(train_df['text_length'].describe())\n",
    "\n",
    "# Histogram of text lengths\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(train_df['text_length'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Text Lengths')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Distribution of labels\n",
    "print(\"\\nDistribution of labels in the training dataset:\")\n",
    "print(train_df['label'].value_counts().sort_index())\n",
    "\n",
    "# Plot of label distribution\n",
    "label_distribution = train_df['label'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_distribution.plot(kind='bar')\n",
    "plt.title('Distribution of Labels')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(axis='y')\n",
    "plt.show()\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Tokenize all words\n",
    "stop_words = set([\"a\", \"an\", \"the\", \"and\", \"or\", \"but\", \"if\", \"in\", \"on\", \"with\", \"as\", \"of\", \"at\", \"by\", \"for\", \"from\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"])\n",
    "all_words = train_df['text'].apply(tokenize).sum()\n",
    "\n",
    "# Find most common words\n",
    "word_counts = Counter(all_words)\n",
    "common_words = word_counts.most_common(20)\n",
    "\n",
    "# Generate WordCloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)\n",
    "\n",
    "# Plot WordCloud\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Most Common Words in Texts')\n",
    "plt.show()\n",
    "\n",
    "# Text lengths grouped by label and described\n",
    "text_length_by_label = train_df.groupby('label')['text_length'].describe()\n",
    "\n",
    "# Boxplot of text lengths by label\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_df.boxplot(column='text_length', by='label', grid=False)\n",
    "plt.title('Text Lengths by Label')\n",
    "plt.suptitle('')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Text Length')\n",
    "plt.show()\n",
    "\n",
    "# Output text lengths by label\n",
    "print(\"\\nText lengths by label:\")\n",
    "print(text_length_by_label)\n",
    "\n",
    "# Replace abbreviations in test data\n",
    "test_df['text'] = test_df['text'].apply(replace_abbreviations)\n",
    "\n",
    "# Initial training and evaluation\n",
    "models = {}\n",
    "results = {}\n",
    "for model_name in model_names.keys():\n",
    "    model_dir = f\"./models/{model_name}\"\n",
    "    if os.path.exists(model_dir):\n",
    "        logger.info(f\"Loading existing model: {model_name}\")\n",
    "        model, tokenizer, eval_results = load_model(model_name)\n",
    "        if 'eval_f1' not in eval_results:\n",
    "            logger.info(f\"Re-evaluating model: {model_name} to include 'eval_f1' metric.\")\n",
    "            torch.cuda.empty_cache()\n",
    "            model, tokenizer, eval_results = train_model(model_name, train_df)\n",
    "    else:\n",
    "        # Clear CUDA cache before training each model\n",
    "        torch.cuda.empty_cache()\n",
    "        model, tokenizer, eval_results = train_model(model_name, train_df)\n",
    "    models[model_name] = (model, tokenizer)\n",
    "    results[model_name] = eval_results\n",
    "\n",
    "if not results:\n",
    "    logger.info(\"No models were trained. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "# Verify that eval_f1 score is in results\n",
    "for model_name, eval_results in results.items():\n",
    "    if 'eval_f1' not in eval_results:\n",
    "        raise KeyError(f\"Model {model_name} evaluation results do not contain 'eval_f1' metric.\")\n",
    "\n",
    "# Select the best model based on eval_f1 score\n",
    "best_model_name = max(results, key=lambda k: results[k]['eval_f1'])\n",
    "logger.info(f\"Best model: {best_model_name} with F1 score: {results[best_model_name]['eval_f1']}\")\n",
    "\n",
    "# Clear CUDA cache before fine-tuning\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Check if the fine-tuned model exists\n",
    "fine_tuned_model_dir = f\"./models/{best_model_name}_fine_tuned\"\n",
    "if os.path.exists(fine_tuned_model_dir):\n",
    "    logger.info(f\"Loading existing fine-tuned model: {best_model_name}\")\n",
    "    best_model, best_tokenizer, best_eval_results = load_model(f\"{best_model_name}_fine_tuned\")\n",
    "else:\n",
    "    # Fine-tune the best model using Optuna\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    best_trial = study.best_trial\n",
    "    logger.info(f\"Best trial: {best_trial.params}\")\n",
    "\n",
    "    # Train the best model with the best hyperparameters\n",
    "    best_learning_rate = best_trial.params['learning_rate']\n",
    "    best_batch_size = best_trial.params['batch_size']\n",
    "    best_model, best_tokenizer, best_eval_results = train_model(best_model_name, train_df, best_learning_rate, best_batch_size, use_early_stopping=True)\n",
    "\n",
    "    # Save the fine-tuned model and evaluation results\n",
    "    best_model.save_pretrained(fine_tuned_model_dir)\n",
    "    best_tokenizer.save_pretrained(fine_tuned_model_dir)\n",
    "    with open(f\"./models/{best_model_name}_fine_tuned_eval_results.json\", \"w\") as f:\n",
    "        json.dump(best_eval_results, f)\n",
    "\n",
    "def predict(model, tokenizer, text):\n",
    "    text = replace_abbreviations(text)  # Replace abbreviations in the input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512).to(device)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1).item()\n",
    "    return predictions\n",
    "\n",
    "# Gradio interface\n",
    "def predict_sample(sample_index):\n",
    "    sample = test_df.iloc[sample_index]\n",
    "    text = sample['text']\n",
    "    ground_truth = sample['label']\n",
    "\n",
    "    predictions = {}\n",
    "    for model_name, (model, tokenizer) in models.items():\n",
    "        predictions[model_name] = predict(model, tokenizer, text)\n",
    "    \n",
    "    predictions['Fine-Tuned'] = predict(best_model, best_tokenizer, text)\n",
    "    \n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"predictions\": predictions\n",
    "    }\n",
    "\n",
    "sample_dropdown = gr.inputs.Dropdown(choices=[i for i in range(len(test_df))], label=\"Select a Sample\")\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_sample,\n",
    "    inputs=sample_dropdown,\n",
    "    outputs=\"json\",\n",
    "    description=\"Sentiment Analysis Prediction\"\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b8bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
