{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbf0ceb-2f87-48fd-b119-b3017c54ff6c",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/Natural-Language-Processing-SS24/task2/blob/main/Rezepte_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b304ee6a-9ff1-4d9a-b0a5-d0f6ef378fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn\n",
    "!pip install transformers\n",
    "!pip install optuna\n",
    "!pip install optuna-integration\n",
    "!pip install torch\n",
    "!pip install python-docx\n",
    "!pip install accelerate -U\n",
    "!pip install transformers[torch]\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da73642-354b-4fc7-92e1-8f157a7e46e9",
   "metadata": {},
   "source": [
    "## Bibliotheken importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7c8e1-3248-4d6d-9533-ba3158c69c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import ast\n",
    "from google.colab import files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    BertTokenizer, BertForSequenceClassification,\n",
    "    DistilBertTokenizer, DistilBertForSequenceClassification,\n",
    "    Trainer, TrainingArguments\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gradio as gr\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a42332-137d-4ece-94b9-2352d124f687",
   "metadata": {},
   "source": [
    "## Dateien hochladen und laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce286a45-b382-4cc0-87ba-2b8f3f2db9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dateien hochladen\n",
    "uploaded = files.upload()\n",
    "\n",
    "training_data_path = 'Recipes_Training.csv'\n",
    "test_data_path = 'Recipes_Test.csv'\n",
    "\n",
    "# Laden der Datensätze\n",
    "training_df = pd.read_csv(training_data_path, delimiter=';')\n",
    "test_df = pd.read_csv(test_data_path, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd22367-23ce-4e29-9384-95a2a4b415b9",
   "metadata": {},
   "source": [
    "## Explorative Datenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919be508-44e3-4a17-aa01-0ebab730e994",
   "metadata": {},
   "source": [
    "### Daten anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9cd9e-9958-4943-9395-1d0e53a99b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informationen und erste Zeilen der DataFrames anzeigen\n",
    "print(training_df.info())\n",
    "print(training_df.head())\n",
    "print(test_df.info())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38544470-4c2e-4a2e-b436-b5199e23d91b",
   "metadata": {},
   "source": [
    "### Verteilung der Küchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e96a29a-17d1-4dae-864b-4af8faf959cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verteilung der Küchen\n",
    "cuisine_counts = training_df['cuisine'].value_counts()\n",
    "plt.figure(figsize=(12, 6))\n",
    "cuisine_counts.plot(kind='bar')\n",
    "plt.title('Verteilung der Küchen im Trainingsdatensatz')\n",
    "plt.xlabel('Küche')\n",
    "plt.ylabel('Anzahl der Rezepte')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f85070-4963-4c63-a4fc-05d69baa413a",
   "metadata": {},
   "source": [
    "### Häufigste Zutaten analysieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a49cf-17ca-4b05-a3d9-44aa94f0b0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Häufigste Zutaten\n",
    "all_ingredients = []\n",
    "for ingredients_list in training_df['ingredients']:\n",
    "    ingredients = ast.literal_eval(ingredients_list)\n",
    "    all_ingredients.extend(ingredients)\n",
    "\n",
    "ingredient_counts = Counter(all_ingredients)\n",
    "\n",
    "# Top 20 häufigste Zutaten\n",
    "top_ingredients = ingredient_counts.most_common(20)\n",
    "ingredients, counts = zip(*top_ingredients)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(ingredients, counts)\n",
    "plt.title('Top 20 häufigste Zutaten')\n",
    "plt.xlabel('Zutat')\n",
    "plt.ylabel('Häufigkeit')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2adce1-5a4b-4aca-85f9-3f3430abe620",
   "metadata": {},
   "source": [
    "### Top-Zutaten für jede Küche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93b7cc-3552-466b-9e0d-d34f5845f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, um die Top-Zutaten für jede Küche zu erhalten\n",
    "def get_top_ingredients_by_cuisine(cuisine):\n",
    "    cuisine_data = training_df[training_df['cuisine'] == cuisine]\n",
    "    all_ingredients = []\n",
    "    for ingredients_list in cuisine_data['ingredients']:\n",
    "        ingredients = ast.literal_eval(ingredients_list)\n",
    "        all_ingredients.extend(ingredients)\n",
    "    ingredient_counts = Counter(all_ingredients)\n",
    "    return ingredient_counts.most_common(10)\n",
    "\n",
    "# Top-Zutaten für jede Küche\n",
    "cuisines = training_df['cuisine'].unique()\n",
    "top_ingredients_by_cuisine = {cuisine: get_top_ingredients_by_cuisine(cuisine) for cuisine in cuisines}\n",
    "\n",
    "# Top-Zutaten für jede Küche plotten\n",
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(16, 20))\n",
    "fig.tight_layout(pad=6.0)\n",
    "\n",
    "for ax, (cuisine, top_ingredients) in zip(axes.flatten(), top_ingredients_by_cuisine.items()):\n",
    "    ingredients, counts = zip(*top_ingredients)\n",
    "    ax.bar(ingredients, counts)\n",
    "    ax.set_title(f'Top 10 Zutaten in {cuisine.capitalize()} Küche')\n",
    "    ax.set_xlabel('Zutat')\n",
    "    ax.set_ylabel('Häufigkeit')\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb485f1f-9c47-4ab0-a58c-5da5afb93de8",
   "metadata": {},
   "source": [
    "## Datenvorbereitung für Modell-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2da3a-1ee4-48df-af71-5fbb0e9c2f91",
   "metadata": {},
   "source": [
    "### Trainings- und Validierungsdaten splitten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcaa563-85f0-48be-ade4-7cd04a9009c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainings- und Validierungsdaten splitten\n",
    "train_df, val_df = train_test_split(training_df, test_size=0.2, stratify=training_df['cuisine'], random_state=42)\n",
    "\n",
    "# Datensätze in Hugging Face Dataset-Format umwandeln\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "datasets = DatasetDict({\"train\": train_dataset, \"val\": val_dataset})\n",
    "\n",
    "# Maximale Länge für Padding und Trunkierung definieren\n",
    "max_length = 128\n",
    "\n",
    "# Label-Konvertierung erstellen\n",
    "label2id = {label: i for i, label in enumerate(training_df['cuisine'].unique())}\n",
    "id2label = {i: label for label, i in label2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426a5714-0585-4c5e-ac6c-b33a0d8a4f23",
   "metadata": {},
   "source": [
    "### Text und Labels vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980c60e-6974-4ba4-888f-4520b31dbde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text und Labels vorbereiten\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples['ingredients'], padding='max_length', truncation=True, max_length=max_length)\n",
    "    inputs['labels'] = [label2id[label] for label in examples['cuisine']]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed641fdc-95c7-4cdc-b86d-1cfefa46d980",
   "metadata": {},
   "source": [
    "## Funktion zur Modell-Trainierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf082e54-2849-472f-9da1-ee0caa146cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Modell-Trainierung\n",
    "def train_model(model_name, model_class, tokenizer_class, num_labels, num_epochs=3):\n",
    "    global tokenizer\n",
    "    tokenizer = tokenizer_class.from_pretrained(model_name)\n",
    "    \n",
    "    tokenized_datasets = datasets.map(preprocess_function, batched=True)\n",
    "\n",
    "    model = model_class.from_pretrained(model_name, num_labels=num_labels)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=10,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=0.01,\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"val\"],\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluierung\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation results for {model_name}:\")\n",
    "    print(eval_results)\n",
    "    \n",
    "    # Vorhersagen und Berechnung der Metriken\n",
    "    val_predictions = trainer.predict(tokenized_datasets[\"val\"]).predictions\n",
    "    val_predictions = np.argmax(val_predictions, axis=1)\n",
    "    val_labels = tokenized_datasets[\"val\"]['labels']\n",
    "    \n",
    "    # Klassifikationsbericht\n",
    "    print(f\"Classification Report for {model_name}:\")\n",
    "    print(classification_report(val_labels, val_predictions, target_names=list(label2id.keys())))\n",
    "    \n",
    "    # Konfusionsmatrix\n",
    "    cm = confusion_matrix(val_labels, val_predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=list(label2id.keys()), yticklabels=list(label2id.keys()), cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53c468-1ad8-4943-992e-948b5a349b05",
   "metadata": {},
   "source": [
    "## Modelle trainieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46891821-3135-4814-8f33-8aca496cd4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Klassen\n",
    "num_labels = len(training_df['cuisine'].unique())\n",
    "\n",
    "# Modelle trainieren\n",
    "distilbert_model = train_model('distilbert-base-uncased', DistilBertForSequenceClassification, DistilBertTokenizer, num_labels, num_epochs=3)\n",
    "bert_base_model = train_model('bert-base-uncased', BertForSequenceClassification, BertTokenizer, num_labels, num_epochs=3)\n",
    "bert_large_model = train_model('bert-large-uncased', BertForSequenceClassification, BertTokenizer, num_labels, num_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9a17d-45e2-49bc-b104-9bc3c34016bc",
   "metadata": {},
   "source": [
    "## Gradio-Oberfläche erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5f103d-a0ce-4f14-81bc-7c57f2a3fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion zur Vorhersage mit allen Modellen\n",
    "def predict_recipe(recipe):\n",
    "    inputs = tokenizer(recipe, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "    predictions = {}\n",
    "\n",
    "    # DistilBERT\n",
    "    with torch.no_grad():\n",
    "        outputs = distilbert_model(**inputs)\n",
    "    distilbert_prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    predictions['DistilBERT'] = id2label[distilbert_prediction]\n",
    "\n",
    "    # BERT Base\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_base_model(**inputs)\n",
    "    bert_base_prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    predictions['BERT Base'] = id2label[bert_base_prediction]\n",
    "\n",
    "    # BERT Large\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_large_model(**inputs)\n",
    "    bert_large_prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    predictions['BERT Large'] = id2label[bert_large_prediction]\n",
    "\n",
    "    actual_cuisine = training_df[training_df['ingredients'].apply(lambda x: recipe in x)].iloc[0]['cuisine']\n",
    "    return recipe, predictions, actual_cuisine\n",
    "\n",
    "# Gradio-Oberfläche\n",
    "def show_recipe_options():\n",
    "    recipes = training_df['ingredients'].apply(lambda x: x[:50] + '...').tolist()\n",
    "    return recipes\n",
    "\n",
    "gr.Interface(\n",
    "    fn=predict_recipe,\n",
    "    inputs=gr.Dropdown(show_recipe_options(), label=\"Select a Recipe\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Full Recipe\"),\n",
    "        gr.Textbox(label=\"Predictions\"),\n",
    "        gr.Textbox(label=\"Actual Cuisine\"),\n",
    "    ],\n",
    "    live=True\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a8d3b-db3a-46fb-8f85-9d511cb9d524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
